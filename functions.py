import google.generativeai as genai
import os
import textwrap
import pandas as pd
import numpy as np
import streamlit as st
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader

#agent functions
def menu():
    bar1, bar2= st.columns([1,1])
    bar1.page_link("meizixiangshenme.py", label="äº†å¦‚æŒ‡æŽŒ", icon="ðŸ‘§")
    bar2.page_link("pages/junshiliangji.py", label="åç­¹å¸·å¹„", icon="ðŸ’¡")
    st.write("")

def make_prompt(prompt, meizi_message):
  #escaped = passage.replace("'", "").replace('"', "").replace("\n", " ")
  prompt = textwrap.dedent("""
ä½ æ˜¯ä¸€ä¸ªæ‹çˆ±ä¸“å®¶ï¼Œä½ ä¸“é—¨å¸®åŠ©ç”·ç”Ÿç†è§£ä»–ä»¬å–œæ¬¢çš„å¥³ç”Ÿå¯„ç»™ä»–ä»¬çš„è®¯æ¯ï¼Œè§£è¯»å¥³ç”Ÿè®¯æ¯èƒŒåŽçš„å«ä¹‰å’Œå¥¹ä»¬çš„å¿ƒæƒ…ä¸Žæƒ³æ³•ã€‚
ç”·ç”Ÿå°†ä¼šå‘ä½ è¯·æ±‚å†™è®¯æ¯ç»™å¥³ç”Ÿçš„å»ºè®®ï¼Œå°¤å…¶æ˜¯å¸Œæœ›ä½ èƒ½ç»™å‡ºä¾‹å­ï¼Œä»¥æ‰“åŠ¨å¯¹æ–¹çš„å¿ƒã€‚
ç”·ç”Ÿè¯·æ±‚: {prompt}
ä»¥ä¸‹å¼€å§‹æ˜¯å¥³ç”Ÿå’Œç”·ç”Ÿçš„ç”µè¯è®¯æ¯ï¼š{meizi_message}
""").format(prompt=prompt, meizi_message=meizi_message)
  return prompt

def make_prompt2(prompt):
  #escaped = passage.replace("'", "").replace('"', "").replace("\n", " ")
  prompt = textwrap.dedent("""
ä½ æ˜¯ä¸€ä¸ªæ‹çˆ±ä¸“å®¶ã€‚
ä»¥ä¸‹æ˜¯ç”·ç”Ÿè¯·æ±‚: {prompt}                          
""").format(prompt=prompt)
  return prompt

def gemini_chat(full_prompt):
    model = genai.GenerativeModel('gemini-1.5-flash-latest')
    answer = model.generate_content(full_prompt)
    for chunk in answer.text:
        yield chunk   

def update_knowledge():
    docdir='rag_docs/'
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
    table=pd.DataFrame(columns=['document', 'content','embedding','relevant score'])
    i=0
    for doc in os.listdir(docdir):
        docsplit=TextLoader(docdir+doc,encoding='utf8').load_and_split(text_splitter)
        for chunk in docsplit:
            embedding = genai.embed_content(model='models/text-embedding-004',content=chunk.page_content,task_type="retrieval_query")
            table.loc[i]=[chunk.metadata['source'],chunk.page_content,embedding['embedding'],0]
            i=i+1
    return table

def retrieve_knowledge(query):
  rank_threshold=0.5
  ranking=10
  readparquet=pd.read_parquet('embbed_table.parquet.gzip')
  query_embedding = genai.embed_content(model='models/text-embedding-004',
                                        content=query,
                                        task_type="retrieval_query")
  readparquet['relevant score'] = np.dot(np.stack(readparquet['embedding']), query_embedding["embedding"])
  relevant_knowledge=readparquet.loc[(readparquet['relevant score']>rank_threshold)].sort_values('relevant score',ascending=False).head(ranking)
  text_list=[]
  i=1
  for t in relevant_knowledge['content'].apply(lambda x: x.replace("\ufeff", "")):
    text_list.append("KNOWLEDGE "+str(i)+": "+t+" ")
    i=i+1

  return "".join(text_list)